<!-- ===================== PROJECT TITLE ===================== -->
# ğŸ¥ Code-Mixed Multilingual YouTube Comment Analyzer  

A multilingual **multi-task transformer model** built using **XLM-RoBERTa**, performing:  
- ğŸ­ **Sentiment Analysis**  
- â˜£ï¸ **Toxicity Detection**  
- âš ï¸ **Anomaly Detection**  

on **YouTube comments**, including **code-mixed** (English + regional language) and **multilingual** text.

---

<!-- ===================== OVERVIEW ===================== -->
## ğŸš€ Overview  

This project builds an **end-to-end AI pipeline** that:  
1. **Fetches YouTube comments** via YouTube Data API.  
2. **Preprocesses text** (emoji handling, cleaning, language detection).  
3. **Generates pseudo-labels** for sentiment & toxicity.  
4. **Trains a multi-task transformer (XLM-R)** for three tasks jointly.  
5. **Evaluates** using F1-score, accuracy, and uncertainty-weighted loss.  
6. **Deploys** via a **Streamlit dashboard** for real-time analysis.  

---

<!-- ===================== FEATURES ===================== -->
## ğŸ§© Features  

âœ… Multi-task learning (sentiment, toxicity, anomaly)  
âœ… Cross-lingual XLM-RoBERTa backbone  
âœ… Weighted loss via **homoscedastic uncertainty**  
âœ… Automatic comment collection  
âœ… Streamlit UI for testing  
âœ… Modular, clean architecture  

---

<!-- ===================== ARCHITECTURE ===================== -->
## ğŸ§  Architecture  
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  YouTube API Comment Fetch â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ Preprocessing Layer â”‚
             â”‚ (clean + label data)â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  XLM-R Base Encoder   â”‚
            â”‚ (shared representations)â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                   â”‚    â”‚    â”‚
             â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â–¼â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
             â”‚ Task Heads:          â”‚
             â”‚ Sentiment | Toxicity â”‚
             â”‚ Anomaly             â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---

<!-- ===================== LOSS EQUATION ===================== -->
## ğŸ§® Weighted Multi-Task Loss  

To balance task importance, the model learns **uncertainty weights**:
<img width="765" height="163" alt="image" src="https://github.com/user-attachments/assets/78e35f13-1899-483f-8568-087172f505bf" />


ğŸ§  **Intuition:**  
A task with higher uncertainty (noisier data) contributes less to the total loss.

---

<!-- ===================== STRUCTURE ===================== -->
## ğŸ“ Project Structure  
<img width="491" height="435" alt="image" src="https://github.com/user-attachments/assets/d3a0a73e-5525-4f64-a085-6822264a11c2" />
<!-- ===================================================== -->
<!-- =============== âš™ï¸ SETUP AND INSTALLATION =============== -->
<!-- ===================================================== -->


## âš™ï¸ Setup & Installation  

Follow these steps to set up and run the **Code-Mixed Multilingual YouTube Comment Analyzer** on your system:  

### 1ï¸âƒ£ Clone the repository
git clone https://github.com/Dhanu2865/Code-mixed-multilingual-sentiment-analysis-on-youtube-comments.git
cd Code-mixed-multilingual-sentiment-analysis-on-youtube-comments

### 2ï¸âƒ£ Create and activate a virtual environment
python -m venv venv

### â–¶ï¸ Activate the environment
### On Windows:
venv\Scripts\activate

### On Mac/Linux:
source venv/bin/activate

### 3ï¸âƒ£ Install all dependencies
pip install -r requirements.txt

### 4ï¸âƒ£ (Optional) Download trained model weights
### If youâ€™ve stored weights externally (Google Drive / Hugging Face)
python download_weights.py

### 5ï¸âƒ£ Run the Streamlit web app
streamlit run app/app.py


## Model Output
<img width="992" height="210" alt="image" src="https://github.com/user-attachments/assets/96b50140-8ab3-42ad-8a18-1726ebd39a41" />
<img width="1071" height="273" alt="image" src="https://github.com/user-attachments/assets/085a70dd-e3b5-4cae-89d1-28222c37d864" />

<img width="968" height="346" alt="image" src="https://github.com/user-attachments/assets/3304156a-840d-4cf7-a7ef-5290b889e83e" />

---

---

## ğŸ§° Requirements  

Make sure you have **Python 3.8+** installed and the following dependencies:  

- ğŸ§  **torch** â€” Deep learning framework for model training  
- ğŸ¤– **transformers** â€” Pretrained XLM-RoBERTa and NLP utilities  
- ğŸ“Š **pandas** â€” Data manipulation and analysis  
- ğŸ”¢ **numpy** â€” Numerical computing support  
- ğŸ“ˆ **matplotlib** â€” Visualizations and charts  
- â³ **tqdm** â€” Progress bars for training and data processing  
- ğŸ¥ **google-api-python-client** â€” Fetch YouTube comments via API  
- ğŸŒ **streamlit** â€” Frontend web app for model inference  
- ğŸ§® **scikit-learn** â€” Metrics, evaluation, and preprocessing utilities  
- ğŸ˜‚ **emoji** â€” Handle emoji text and tokens  
- ğŸŒ **langdetect** â€” Detect language for code-mixed data  
- â˜ï¸ **gdown** â€” Download pretrained weights from Google Drive  

You can install all dependencies at once using:  
pip install -r requirements.txt

## ğŸ’¡ Future Work  

- ğŸŒ Expand to more Indian languages (Tamil, Hindi, etc.)  
- ğŸ§  Add explainability (attention heatmaps)  
- ğŸ“ Include summarization as an additional downstream task  
- â˜ï¸ Host app on **Streamlit Cloud** or **Hugging Face Spaces**  

---

## ğŸ“œ License  

Released under the **MIT License**.  
You are free to use, modify, and distribute this project with proper attribution.

---


